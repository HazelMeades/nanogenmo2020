{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following demo: https://medium.com/better-programming/nlp-with-python-build-a-haiku-machine-in-50-lines-of-code-6c7b6de959e3\n",
    "\n",
    "#import nltk\n",
    "#import markovify\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import syllapy\n",
    "count = syllapy.count('additional')\n",
    "import random\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\") #loading a language model\n",
    "matcher2 = Matcher(nlp.vocab) #https://spacy.io/api/matcher\n",
    "matcher3 = Matcher(nlp.vocab)\n",
    "matcher4 = Matcher(nlp.vocab)\n",
    "\n",
    "# POS = Part of Speech\n",
    "pattern = [{'POS':  {\"IN\": [\"NOUN\", \"ADP\", \"ADJ\", \"ADV\"]} },\n",
    "           {'POS':  {\"IN\": [\"NOUN\", \"VERB\"]} }]\n",
    "matcher2.add(\"TwoWords\", None, pattern)\n",
    "\n",
    "pattern = [{'POS':  {\"IN\": [\"NOUN\", \"ADP\", \"ADJ\", \"ADV\"]} },\n",
    "           {'IS_ASCII': True, 'IS_PUNCT': False, 'IS_SPACE': False},\n",
    "           {'POS':  {\"IN\": [\"NOUN\", \"VERB\", \"ADJ\", \"ADV\"]} }]\n",
    "matcher3.add(\"ThreeWords\", None, pattern)\n",
    "\n",
    "pattern = [{'POS':  {\"IN\": [\"NOUN\", \"ADP\", \"ADJ\", \"ADV\"]} },\n",
    "           {'IS_ASCII': True, 'IS_PUNCT': False, 'IS_SPACE': False},\n",
    "           {'IS_ASCII': True, 'IS_PUNCT': False, 'IS_SPACE': False},\n",
    "           {'POS':  {\"IN\": [\"NOUN\", \"VERB\", \"ADJ\", \"ADV\"]} }]\n",
    "matcher4.add(\"FourWords\", None, pattern)\n",
    "\n",
    "\n",
    "# Doc = a container for accessing linguistic annotations. \n",
    "doc = nlp(open(\"nanowrimo/combined-allfinished-nanos-nofluff.txt\").read())\n",
    "\n",
    "# Loads patterns?\n",
    "matches2 = matcher2(doc)\n",
    "matches3 = matcher3(doc)\n",
    "matches4 = matcher4(doc)\n",
    "\n",
    "g_5 = []\n",
    "g_7 = []\n",
    "\n",
    "# Span = A slice from a Doc object.\n",
    "for match_id, start, end in matches2 + matches3 + matches4:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    #print('span is %s' %(span))\n",
    "\n",
    "    # Token = a word, punctuation symbol, whitespace, etc. \n",
    "    syl_count = 0\n",
    "    count = 0\n",
    "    for token in span:\n",
    "        count += 1\n",
    "        syl_count += syllapy.count(token.text)\n",
    "        #print('%d: %d %s' %(count, syl_count, token.text))\n",
    "    if syl_count == 5:\n",
    "        if span.text not in g_5:\n",
    "            g_5.append(span.text)\n",
    "    if syl_count == 7:\n",
    "        if span.text not in g_7:\n",
    "            g_7.append(span.text)\n",
    "#print('%d tokens %d syllables found' %(count, syl_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_haiku():\n",
    "    print(\"%s\\n%s\\n%s\" %(random.choice(g_5),random.choice(g_7),random.choice(g_5)))\n",
    "    input(\"\\n\")\n",
    "\n",
    "my_haiku()\n",
    "    \n",
    "#print(\"Enter for a new haiku. ^C to quit\\n\")\n",
    "#while (True):\n",
    "    #print(\"%s\\n%s\\n%s\" %(random.choice(g_5),random.choice(g_7),random.choice(g_5)))\n",
    "    #input(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
